p8105_hw2_vc2692
================
2025-09-27

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

## Cleaning pols-month.csv

``` r
pols_month_df =
  read_csv("dataset/fivethirtyeight_datasets/pols-month.csv") |> 
  separate (
    mon, into = c("year", "month", "day"), sep = "-"
  ) |> 
  mutate(month = month.name[as.integer(month)]) |> 
  mutate(month = str_to_lower(month),
         year = as.integer(year)) |> 
  pivot_longer(
    cols = c(prez_gop, prez_dem),
    names_to = "president",
    values_to = "president_value",
    names_prefix = "prez_"
  ) |> 
  filter(president_value == 1) |> 
  select (-day, -president_value)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Cleaning snp.csv

``` r
snp_df = 
  read_csv("dataset/fivethirtyeight_datasets/snp.csv") |> 
  separate (
    date, into = c("month", "day", "year"), sep = "/"
  ) |> 
  mutate(month = month.name[as.integer(month)]) |> 
  mutate(month = str_to_lower(month)) |> 
  select(-day) |> 
  mutate(
    year_int = as.integer(year),
    year_full = if_else(year_int >= 0  & year_int <=15, 2000 + year_int, 1900 + year_int)
  ) |> 
  select(-year, -year_int) |> 
  rename(year = year_full) |> 
  relocate(year)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## cleaning unemployment.csv

``` r
unemployment_df = 
  read_csv("dataset/fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percent_unemp"
  ) |> 
   mutate(month = month.name[match(month, month)]) |> 
  mutate(month = str_to_lower(month))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Joining the three datasets

``` r
pols_snp_joined =
  left_join(pols_month_df, snp_df, by = c("year", "month"))
all_joined = 
  left_join(pols_snp_joined, unemployment_df, by = c("year", "month"))
```

The three datasets that were joined in problem 1 are `pols-month`, `snp`
and `unemployement`. `Pols_month_df` included data on the number of
national politicians who are democratic or republican from January
1947-June 2015. `Snp_df` included the closing values of the S&P stock
index from each month from January 1950-July 2015. `Unemployment_df`
included the percentage of unemployment for each month from January
1948-December 2015. The resulting joined data set has 817 observations
and 11 variables. It includes information from January 1947-June 2015,
since `snp_df` was merged into `pols_month_df`, and then `unemployment`
was merged last. Key variables include the number of national
politicians who are republican/democrat, along with the unemployment
proportion, and closing values of the S&P stock index.

# Problem 2

## Cleaning Mr Trash Wheel

``` r
mr_trash_df =
  read_excel("dataset/trash_wheel_data_2025.xlsx", 
             sheet = "Mr. Trash Wheel",
             na = c(".", "NA", ""),
             range = "A2:N709" ) |> 
  janitor::clean_names() |> 
  mutate(sports_balls = as.integer(round(sports_balls))) |> 
  mutate(wheel_name = "Mr") |> 
  mutate(year = as.integer(year))
```

## Cleaning Professor Trash Wheel

``` r
professor_trash_df = 
  read_excel("dataset/trash_wheel_data_2025.xlsx", 
             sheet = "Professor Trash Wheel",
             na = c(".", "NA", ""),
             range = "A2:M134" ) |> 
  janitor::clean_names() |>
  filter(dumpster != 119) |> 
  mutate(wheel_name = "Professor") |> 
  mutate(year = as.integer(year))
```

## Cleaning Gwynns Falls Trash Wheel

``` r
gwynns_trash_df = 
  read_excel("dataset/trash_wheel_data_2025.xlsx", 
             sheet = "Gwynns Falls Trash Wheel",
             na = c(".", "NA", ""),
             range = "A2:L351" ) |> 
  janitor::clean_names() |> 
  mutate(wheel_name = "Gwynns Falls") |> 
  mutate(year = as.integer(year))
```

## Joining the three trash wheel datasets

``` r
all_wheels_joined = 
  bind_rows(mr_trash_df, professor_trash_df, gwynns_trash_df) |> 
  relocate(wheel_name)
```

## Summary statistics for description

``` r
professor_total_weight =
  all_wheels_joined |> 
  filter(wheel_name == "Professor") |> 
  summarise(sum(weight_tons, na.rm = TRUE))

cigarettes_gwynn_june2022 = 
  all_wheels_joined |> 
  filter(month == "June", year == 2022, wheel_name == "Gwynns Falls") |> 
  summarise(sum(cigarette_butts, na.rm = TRUE))
```

The `all_wheels_joined` dataframe provides information on water-wheel
vessels that remove trash from Inner Harbor located in Baltimore,
Maryland. It provides information on the number of dumpsters that the
wheels fill with trash, the amounts of different types of litter
collected, and the date at which this data is collected. Some examples
of litter types include plastic bags, cigarette butts, and glass
bottles. There are 1187 observations in the combined dataset, which
include information on trash collected by Mr. Trash Wheel from May
2014-July 2025, Professor Trash Wheel from January 2017-July 2025, and
Gwynns Falls trash wheel from July 2021-July 2025.

For available data, the total weight of trash collected by Professor
Trash Wheel is 279.24 tons. Additionally, the total number of cigarette
butts collected by Gwynns Falls Trash Wheel in June of 2022 was
1.812^{4}.

# Question 3

## Cleaning zillow rental price dataset

``` r
rental_price_df =
  read_csv("dataset/zillow_data/zillow_rental_price_dataset.csv", 
           na = c(".", "NA", "")) |> 
  janitor::clean_names() |> 
  mutate(county_name = str_remove(county_name, " County$")) |> 
  rename(zip_code = region_name) |> 
  rename(county = county_name) |> 
  pivot_longer(
    cols = x2015_01_31:x2024_08_31,
    names_to = "date",
    names_prefix = "x",
    values_to = "rental_price"
  ) |> 
  separate(
    date, into = c("year", "month", "day"), sep = "_"
  ) |>
  relocate(zip_code) |> 
  select(-region_id, -size_rank, -region_type, -state_name, -state, -city, -metro)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

\##Cleaning zipcode dataset

``` r
zip_code_df =
  read_csv("dataset/zillow_data/zip_codes.csv", 
           na = c(".", "NA", "")) |> 
  janitor::clean_names() |> 
  relocate(zip_code) |> 
  select(-state_fips, -county_code, -county_fips, -file_date)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Joining zillow and zipcode dataset

``` r
zillow_and_zips =
  left_join(rental_price_df, zip_code_df, by = c("zip_code", "county")) |> 
  select(year, month, day, county, zip_code, neighborhood, rental_price)
```

The `zillow_and_zips` dataset includes rental price information for a
given zipcode in NYC from January 2015-August 2024. There is also
country and neighborhood information for the given zipcode included in
this dataset. There are 149 unique zip codes and 43 unique
neighborhoods.

\##Zipcodes not in Zillow data

``` r
only_zipcode_dataset_zipcodes = 
  anti_join(zip_code_df, rental_price_df, by = "zip_code")
```

There are 171 that were included in the zip_code_df but not in the
rental_price_df containing information from Zillow. Some zipcodes that
are included in the `only_zipcode_dataset_zipcodes` dataset include
Southeast Bronx, Northeast Bronx, and Hunts Point and Mott Haven. This
may be because these zip codes don’t have any rental buildings/houses
that are included on Zillow.

## Zipcodes with largest price decrease from Jan 2020 to Jan 2021

``` r
ten_largest_price_decrease =
  zillow_and_zips |> 
  filter(year %in% c(2020, 2021)) |> 
  filter(month == "01") |> 
  pivot_wider(
    names_from = year,
    values_from = rental_price) |> 
  mutate( price_diff_2020_2021 = `2020`- `2021`) |> 
  arrange(desc(price_diff_2020_2021)) |> 
  slice_head(n=10) |> 
  select(county, neighborhood,price_diff_2020_2021 )
  
ten_largest_price_decrease
```

    ## # A tibble: 10 × 3
    ##    county   neighborhood                  price_diff_2020_2021
    ##    <chr>    <chr>                                        <dbl>
    ##  1 New York Lower Manhattan                               913.
    ##  2 New York <NA>                                          748.
    ##  3 New York Lower East Side                               714.
    ##  4 New York Gramercy Park and Murray Hill                 712.
    ##  5 New York Chelsea and Clinton                           710.
    ##  6 New York Lower East Side                               710.
    ##  7 New York Lower Manhattan                               706.
    ##  8 New York Lower Manhattan                               698.
    ##  9 New York Greenwich Village and Soho                    686.
    ## 10 New York Gramercy Park and Murray Hill                 685.

The above table shows 10 ZIP codes (along with the borough and
neighborhood) with largest drop in price from January 2020 to 2021. They
are all in in New York County / Manhattan. The top ten decreases range
from \$913 to \$685.
